{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangi\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emotion</td>\n",
       "      <td>pixels</td>\n",
       "      <td>Usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     usage\n",
       "0  emotion                                             pixels     Usage\n",
       "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
       "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
       "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
       "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
       "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "filname = './fer2013.csv'\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "names=['emotion','pixels','usage']\n",
    "df=pd.read_csv('./fer2013.csv',names=names, na_filter=False)\n",
    "im=df['pixels']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "bfde4d91ff367dfa6764202c1b309ea291fb833a"
   },
   "outputs": [],
   "source": [
    "def getData(filname):\n",
    "    # images are 48x48\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(filname):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "435d0e06553e3de3fd982e4a4a86c28018ac3913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "X, Y = getData(filname)\n",
    "num_class = len(set(Y))\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e"
   },
   "outputs": [],
   "source": [
    "# keras with tensorflow backend\n",
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "be4faef86c3c5635697f10939547edd5c8760308"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "3afd36886a65ff49fe48ac73271f7477b574375a"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c8eaecce539d06c983ed73142ac1484dbfa5e970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 2,787,015\n",
      "Trainable params: 2,785,863\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def my_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    "model=my_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "5004be413385dbdf6c3967d34c59e541095ea667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/20\n",
      "32298/32298 [==============================] - 34s 1ms/step - loss: 1.6552 - accuracy: 0.3566 - val_loss: 1.5456 - val_accuracy: 0.4029\n",
      "Epoch 2/20\n",
      "32298/32298 [==============================] - 31s 953us/step - loss: 1.2918 - accuracy: 0.5086 - val_loss: 1.4224 - val_accuracy: 0.4400\n",
      "Epoch 3/20\n",
      "32298/32298 [==============================] - 30s 929us/step - loss: 1.1280 - accuracy: 0.5760 - val_loss: 1.1682 - val_accuracy: 0.5573\n",
      "Epoch 4/20\n",
      "32298/32298 [==============================] - 31s 950us/step - loss: 1.0060 - accuracy: 0.6255 - val_loss: 1.0701 - val_accuracy: 0.5954\n",
      "Epoch 5/20\n",
      "32298/32298 [==============================] - 30s 918us/step - loss: 0.8925 - accuracy: 0.6703 - val_loss: 1.3438 - val_accuracy: 0.5224\n",
      "Epoch 6/20\n",
      "32298/32298 [==============================] - 30s 940us/step - loss: 0.7658 - accuracy: 0.7182 - val_loss: 1.1617 - val_accuracy: 0.5910\n",
      "Epoch 7/20\n",
      "32298/32298 [==============================] - 30s 939us/step - loss: 0.6175 - accuracy: 0.7740 - val_loss: 1.2178 - val_accuracy: 0.5634\n",
      "Epoch 8/20\n",
      "32298/32298 [==============================] - 29s 909us/step - loss: 0.4729 - accuracy: 0.8318 - val_loss: 1.2968 - val_accuracy: 0.5832\n",
      "Epoch 9/20\n",
      "32298/32298 [==============================] - 30s 923us/step - loss: 0.3250 - accuracy: 0.8875 - val_loss: 1.3659 - val_accuracy: 0.5988\n",
      "Epoch 10/20\n",
      "32298/32298 [==============================] - 30s 932us/step - loss: 0.2315 - accuracy: 0.9210 - val_loss: 1.5254 - val_accuracy: 0.6041\n",
      "Epoch 11/20\n",
      "32298/32298 [==============================] - 30s 928us/step - loss: 0.1873 - accuracy: 0.9380 - val_loss: 1.6355 - val_accuracy: 0.6096\n",
      "Epoch 12/20\n",
      "32298/32298 [==============================] - 30s 942us/step - loss: 0.1462 - accuracy: 0.9531 - val_loss: 2.0276 - val_accuracy: 0.5759\n",
      "Epoch 13/20\n",
      "32298/32298 [==============================] - 30s 943us/step - loss: 0.1241 - accuracy: 0.9604 - val_loss: 1.7867 - val_accuracy: 0.6194\n",
      "Epoch 14/20\n",
      "32298/32298 [==============================] - 31s 955us/step - loss: 0.1125 - accuracy: 0.9640 - val_loss: 1.8797 - val_accuracy: 0.6013\n",
      "Epoch 15/20\n",
      "32298/32298 [==============================] - 30s 943us/step - loss: 0.1097 - accuracy: 0.9640 - val_loss: 2.0290 - val_accuracy: 0.6163\n",
      "Epoch 16/20\n",
      "32298/32298 [==============================] - 30s 943us/step - loss: 0.1069 - accuracy: 0.9653 - val_loss: 2.0046 - val_accuracy: 0.6158\n",
      "Epoch 17/20\n",
      "32298/32298 [==============================] - 30s 943us/step - loss: 0.0834 - accuracy: 0.9724 - val_loss: 2.0775 - val_accuracy: 0.6007\n",
      "Epoch 18/20\n",
      "32298/32298 [==============================] - 30s 935us/step - loss: 0.0883 - accuracy: 0.9705 - val_loss: 2.0868 - val_accuracy: 0.6208\n",
      "Epoch 19/20\n",
      "32298/32298 [==============================] - 36s 1ms/step - loss: 0.0824 - accuracy: 0.9736 - val_loss: 2.1733 - val_accuracy: 0.6194\n",
      "Epoch 20/20\n",
      "32298/32298 [==============================] - 33s 1ms/step - loss: 0.0703 - accuracy: 0.9776 - val_loss: 2.1411 - val_accuracy: 0.6216\n"
     ]
    }
   ],
   "source": [
    "path_model='model_filter.h5' # save model at this location after each epoch\n",
    "K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "model=my_model() # create the model\n",
    "K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
    "# fit the model\n",
    "h=model.fit(x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=64, \n",
    "            epochs=20, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,y_test),\n",
    "            shuffle=True,\n",
    "            callbacks=[\n",
    "                ModelCheckpoint(filepath=path_model),\n",
    "            ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
